{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Градиентный_спуск.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-8OLsAV7wrQ"
      },
      "source": [
        "Стохастический градиентый спуск сходится быстрее, чем полный, хотя и менее стабильно. В этом задании вам предлагается реализовать стохастический градиентный спуск и сравнить его с точным вычислением весов линейной модели по скорости работы и значению метрики качества."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgQyWw5o7Nej"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGD1wQgMruJw"
      },
      "source": [
        "### Задание 0\n",
        "\n",
        "Реализуйте класс ```LinearRegressionSGD``` c обучением и и применением линейной регрессии, построенной с помощью стохастического градиентного спуска, с заданным интерфейсом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxdV27R9-uc"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class LinearRegressionSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-4, max_steps=100, w0=None, alpha=1e-4):\n",
        "        \"\"\"\n",
        "        epsilon: разница для нормы изменения весов \n",
        "        max_steps: максимальное количество шагов в градиентном спуске\n",
        "        w0: np.array (d,) - начальные веса\n",
        "        alpha: шаг обучения\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.w_history = []\n",
        "        self.grad_history = []\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        ## На каждом шаге градиентного спуска веса необходимо добавлять в w_history\n",
        "        \n",
        "        l, d = X.shape\n",
        "        \n",
        "        if self.w0 is None:\n",
        "            self.w0 = np.zeros(d)\n",
        "            \n",
        "        self.w = self.w0\n",
        "        \n",
        "        for i in range(self.max_steps):\n",
        "            self.w_history.append(self.w)\n",
        "            \n",
        "            w_new = self.w - self.alpha * self.calc_gradient(X, y)\n",
        "            \n",
        "            if (np.linalg.norm(self.w - w_new) < self.epsilon):\n",
        "                break\n",
        "            \n",
        "            self.w = w_new\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        ---\n",
        "        output: np.array (l)\n",
        "        \"\"\"\n",
        "        \n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "            \n",
        "        l, d = X.shape\n",
        "        y_pred = []\n",
        "        \n",
        "        for i in range(l):\n",
        "            y_pred.append(np.dot(X[i], self.w))\n",
        "            \n",
        "        #y_pred = np.dot(X, self.w)\n",
        "\n",
        "        return np.array(y_pred)\n",
        "    \n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: np.array (d)\n",
        "        \"\"\"\n",
        "\n",
        "        l, d = X.shape\n",
        "        gradient = []\n",
        "        randoom_index = np.random.randint(0, l)\n",
        "        \n",
        "        for j in range(d):\n",
        "            dQ = (2/l) * X[randoom_index, j] * (np.dot(X[randoom_index], self.w) - y[randoom_index])\n",
        "            gradient.append(dQ)\n",
        "            \n",
        "        self.grad_history.append(gradient)\n",
        "\n",
        "        return np.array(gradient)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNOm9-bXpdT3"
      },
      "source": [
        "Проверять работу Вы будете на имеющемся в sklearn наборе данных boston: в нём нужно по информации о доме предсказать его стоимость."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c24JCwes9-pe"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_boston()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(X), y, test_size=0.3, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eIJwWnInXnr"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Метрикой качества в нашей задаче будет MAPE - Mean Absolute Percentage Error. Реализуйте её с заданным интефейсом и вычислите \n",
        "```MAPE(y_test, y_0)```, где ```y_0 = (mean(y_test), mean(y_test), ...)```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znoDavxyuLsi"
      },
      "source": [
        "def MAPE(y_true, y_pred):\n",
        "    \"\"\"\n",
        "        y_true: np.array (l)\n",
        "        y_pred: np.array (l)\n",
        "        ---\n",
        "        output: float [0, +inf)\n",
        "    \"\"\"\n",
        "    l = y_true.shape[0]\n",
        "#     mape = 0\n",
        "    \n",
        "#     for i in range(l):\n",
        "#         mape += abs((y_true[i] - y_pred[i]) / y_true[i])\n",
        "#     mape /= l\n",
        "    mape = (1 / l) * np.linalg.norm(abs((y_true - y_pred)) / abs(y_true), ord = 1)\n",
        "    \n",
        "    return mape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6mTAykeojwp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1080bcc5-3458-43ea-9e24-b7f741c899af"
      },
      "source": [
        "y_0 = np.mean(y_test)\n",
        "\n",
        "MAPE(y_test, y_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37415882976840964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nNy2ITxuMKf"
      },
      "source": [
        "### Задание 2 \n",
        "\n",
        "Обучите ```LinearRegressionSGD``` с базовыми параметрами на тренировочном наборе данных (```X_train```, ```y_train```), сделайте предсказание на тестовых данных ```X_test```, записав результат в переменную ```y_pred_sgd```  и вычислите ошибку MAPE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BIHwAwUvB-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "712cde89-f9ea-45cd-b775-4dfaec71bfa2"
      },
      "source": [
        "sgd = LinearRegressionSGD(alpha = 1e-5)\n",
        "\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sgd = sgd.predict(X_test)\n",
        "\n",
        "MAPE(y_test, y_pred_sgd)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4801742419994511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWappMdMtIPV"
      },
      "source": [
        "### Задание 3\n",
        "\n",
        "Вычислите веса по точной формуле, используя ```X_train``` и ```y_train```; предскажите с их помощью целевую переменную на ```X_test```, записав результат в переменную ```y_pred_lr``` и вычислите ошибку MAPE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjMUlPje9-k0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fed3c31-01eb-4b75-e3e7-3c6f86f08e9f"
      },
      "source": [
        "w = np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(X_train), X_train)), np.transpose(X_train)), y_train)\n",
        "\n",
        "y_pred_lr = np.dot(X_test, w)\n",
        "\n",
        "MAPE(y_test, y_pred_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18953134816375927"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL9L-4cwxZho"
      },
      "source": [
        "## Задание 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZFaUn7yx04u"
      },
      "source": [
        "До этого вы релизовывали модели, в которых не было штрафа за величину весов ```w```. Это может привести к неустойчивости модели и переобучению. Чтобы избежать этих эффектов, предлагается добавить к оптимизируемому функционалу L2-норму весов; таким образом, будем решать задачу гребневой регрессии, Ridge:\n",
        "\n",
        "$$ \\frac{1}{l}(Xw-y)^T(Xw-y) +\\gamma||w||_2 \\rightarrow \\min_{w}. $$\n",
        "\n",
        "\n",
        "Реализуйте обучение такой модели в матричном виде с помощью стохастического градиентного спуска. Класс должен совпадать по набору реализованных функций с ```LinearRegressionVectorized```, разница будет лишь в параметре $\\gamma$, отвечающем за степень регуляризации. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEXqBqmGxWDz"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "class RidgeSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-4, max_steps=1000, w0=None, alpha=1e-2, gamma=0):\n",
        "        \"\"\"\n",
        "        epsilon: разница для нормы изменения весов \n",
        "        max_steps: максимальное количество шагов в градиентном спуске\n",
        "        w0: np.array (d,) - начальные веса\n",
        "        alpha: шаг обучения\n",
        "        gamma: коэффициент регуляризации\n",
        "        \"\"\"\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.w = None\n",
        "        self.w_history = []\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        \n",
        "        l, d = X.shape\n",
        "        \n",
        "        if self.w0 is None:\n",
        "            self.w0 = np.zeros(d)\n",
        "            \n",
        "        self.w = self.w0\n",
        "        \n",
        "        for step in range(self.max_steps):\n",
        "            self.w_history.append(self.w)\n",
        "            \n",
        "            new_w = self.w - self.alpha * self.calc_gradient(X, y)\n",
        "            \n",
        "            if (np.linalg.norm(self.w - new_w) < self.epsilon):\n",
        "                break\n",
        "            \n",
        "            self.w = new_w\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        ---\n",
        "        output: np.array (l)\n",
        "        \"\"\"\n",
        "        \n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "        \n",
        "        return np.dot(X, self.w)\n",
        "\n",
        "    \n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array (l, d)\n",
        "        y: np.array (l)\n",
        "        ---\n",
        "        output: np.array (d)\n",
        "        \"\"\"\n",
        "        \n",
        "        l, d = X.shape\n",
        "        rand_i = np.random.randint(0, l)\n",
        "        \n",
        "        return (2/l) * np.transpose(X[rand_i]) * (np.dot(X[rand_i], self.w) - y[rand_i])\\\n",
        "    + self.gamma * (np.dot(np.transpose(self.w), self.w)) * self.w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t9rqXFu8Pq6"
      },
      "source": [
        "Обучите модель с базовыми параметрами на тренировочных данных и сделайте прогноз y_pred_ridge. Выведите значение MAPE(y_test, y_pred_ridge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A2hak_A8QPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e597d1d-25b9-4c35-fb78-ecdb4edd2298"
      },
      "source": [
        "rsgd = RidgeSGD(alpha = 1e-4)\n",
        "\n",
        "rsgd.fit(X_train, y_train)\n",
        "\n",
        "y_pred_ridge = rsgd.predict(X_test)\n",
        "MAPE(y_test, y_pred_ridge)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3347412926099105"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}